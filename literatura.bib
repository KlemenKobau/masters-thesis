% methodologies
@misc{metodologija_def,
  key          = {metodologija},
  title        = {Metodologija},
  howpublished = {Fran/SSKJ² \url{https://fran.si/133/sskj2-slovar-slovenskega-knjiznega-jezika-2/4494283/metodologija}}
}

@inproceedings{general_big_data_arch_meth,
  author    = {Li, Qing and Xu, Zhiyong and Wei, Hailong and Yu, Chao and Wang, ShuangShuang},
  editor    = {Debruyne, Christophe and Panetto, Herv{\'e} and Gu{\'e}dria, Wided and Bollen, Peter and Ciuciu, Ioana
               and Karabatis, George
               and Meersman, Robert},
  title     = {General Big Data Architecture and Methodology: An Analysis Focused Framework},
  booktitle = {On the Move to Meaningful Internet Systems: OTM 2019 Workshops},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {33--43},
  abstract  = {With the development of information technologies such as cloud computing, the Internet of Things, the mobile Internet, and wireless sensor networks, big data technologies are driving the transformation of information technology and business models. Based on big data technology, data-driven artificial intelligence technology represented by deep learning and reinforcement learning has also been rapidly developed and widely used. But big data technology is also facing a number of challenges. The solution of these problems requires the support of a general big data reference architecture and analytical methodology. Based on the General Architecture Framework (GAF) and the Federal Enterprise Architecture Framework 2.0 (FEAF 2.0), this paper proposes a general big data architecture focusing on big data analysis. Based on GAF and CRISP-DM (cross-industry standard process for data mining), the general methodology and structural approach of big data analysis are proposed.},
  isbn      = {978-3-030-40907-4}
}

@article{iterative_methodology,
  author  = {Tardío, Roberto and Maté, Alejandro and Trujillo, Juan},
  journal = {IEEE Access},
  title   = {An Iterative Methodology for Defining Big Data Analytics Architectures},
  year    = {2020},
  volume  = {8},
  number  = {},
  pages   = {210597-210616},
  doi     = {10.1109/ACCESS.2020.3039455}
}

@article{provisioning_big_data_micro_cloud,
  title   = {Provisioning big data applications as services on containerised cloud: a microservices-based approach},
  author  = {Jing Gao and Wubin Li and Zhuofeng Zhao and Yanbo Han},
  journal = {Int. J. Serv. Technol. Manag.},
  year    = {2020},
  volume  = {26},
  pages   = {167-181}
}

@article{agile_methodologies,
  title     = {Empirical study of agile software development methodologies: A comparative analysis},
  author    = {Matharu, Gurpreet Singh and Mishra, Anju and Singh, Harmeet and Upadhyay, Priyanka},
  journal   = {ACM SIGSOFT Software Engineering Notes},
  volume    = {40},
  number    = {1},
  pages     = {1--6},
  year      = {2015},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{goal_oriented_requirements_engineering,
  title        = {Goal-oriented requirements engineering: A guided tour},
  author       = {Van Lamsweerde, Axel},
  booktitle    = {Proceedings fifth ieee international symposium on requirements engineering},
  pages        = {249--262},
  year         = {2001},
  organization = {IEEE}
}

@article{scrum_meth,
  title   = {The scrum guide},
  author  = {Schwaber, Ken and Sutherland, Jeff},
  journal = {Scrum Alliance},
  volume  = {21},
  number  = {1},
  pages   = {1--38},
  year    = {2011}
}

@inproceedings{kanban_meth,
  title        = {Kanban in software development: A systematic literature review},
  author       = {Ahmad, Muhammad Ovais and Markkula, Jouni and Oivo, Markku},
  booktitle    = {2013 39th Euromicro conference on software engineering and advanced applications},
  pages        = {9--16},
  year         = {2013},
  organization = {IEEE}
}

@book{kanban_book,
  title     = {Successful Evolutionary Change for Your Technology Business},
  author    = {Kanban, AWS In},
  year      = {2010},
  publisher = {Blue Hole Press}
}

@article{extreme_prog_meth,
  title     = {Embracing change with extreme programming},
  author    = {Beck, Kent},
  journal   = {Computer},
  volume    = {32},
  number    = {10},
  pages     = {70--77},
  year      = {1999},
  publisher = {Ieee}
}

@inproceedings{waterfall_meth,
  title        = {Comparing extreme programming and Waterfall project results},
  author       = {Ji, Feng and Sedano, Todd},
  booktitle    = {2011 24th IEEE-CS Conference on Software Engineering Education and Training (CSEE\&T)},
  pages        = {482--486},
  year         = {2011},
  organization = {IEEE}
}

@inproceedings{devops_meth,
  title     = {What is DevOps? A systematic mapping study on definitions and practices},
  author    = {Jabbari, Ramtin and bin Ali, Nauman and Petersen, Kai and Tanveer, Binish},
  booktitle = {Proceedings of the Scientific Workshop Proceedings of XP2016},
  pages     = {1--11},
  year      = {2016}
}

@article{reference_architecture_classification_technologies,
  title        = {Reference Architecture and Classification of Technologies, Products and Services for Big Data Systems},
  volume       = {2},
  issn         = {2214-5796},
  doi          = {10.1016/j.bdr.2015.01.001},
  abstractnote = {Many business cases exploiting big data have been realised in recent years; Twitter, LinkedIn, and Facebook are examples of companies in the social networking domain. Other big data use cases have focused on capturing of value from streaming of movies (Netflix), monitoring of network traffic, or improvement of processes in the manufacturing industry. Also, implementation architectures of the use cases have been published. However, conceptual work integrating the approaches into one coherent reference architecture has been limited. The contribution of this paper is technology independent reference architecture for big data systems, which is based on analysis of published implementation architectures of big data use cases. An additional contribution is classification of related implementation technologies and products/services, which is based on analysis of the published use cases and survey of related work. The reference architecture and associated classification are aimed for facilitating architecture design and selection of technologies or commercial solutions, when constructing big data systems.},
  number       = {4},
  journal      = {Big Data Research},
  author       = {Pääkkönen, Pekka and Pakkala, Daniel},
  year         = {2015},
  month        = {Dec},
  pages        = {166--186},
  language     = {en}
}
@inproceedings{reference_architecture_bd,
  title        = {A reference architecture for big data systems},
  doi          = {10.1109/SKIMA.2016.7916249},
  abstractnote = {Over dozens of years, applying new IT technologies into organizations has always been a big concern for business. Big data certainly is a new concept exciting business. To be able to access more data and empower to analysis big data requires new big data platforms. However, there still remains limited reference architecture for big data systems. In this paper, based on existing reference architecture of big data systems, we propose new high level abstract reference architecture and related reference architecture notations, that better express the overall architecture. The new reference architecture is verified using one existing case and an additional new use case.},
  booktitle    = {2016 10th International Conference on Software, Knowledge, Information Management and Applications (SKIMA)},
  author       = {Sang, Go Muan and Xu, Lai and de Vrieze, Paul},
  year         = {2016},
  month        = {Dec},
  pages        = {370--375}
}

% Big data

@article{big_data_analytics_societal_impact,
  title     = {Big data \& analytics for societal impact: Recent research and trends},
  author    = {Gupta, Ashish and Deokar, Amit and Iyer, Lakshmi and Sharda, Ramesh and Schrader, Dave},
  journal   = {Information Systems Frontiers},
  volume    = {20},
  number    = {2},
  pages     = {185--194},
  year      = {2018},
  publisher = {Springer}
}

@article{bigprovision,
  title     = {Bigprovision: a provisioning framework for big data analytics},
  author    = {Li, Huan and Lu, Kejie and Meng, Shicong},
  journal   = {Ieee Network},
  volume    = {29},
  number    = {5},
  pages     = {50--56},
  year      = {2015},
  publisher = {IEEE}
}

@article{vehicle_networks,
  author  = {Zhou, Zhenyu and Yu, Houjian and xu, Lei and Zhang, Yan and Mumtaz, Shahid and Rodriguez, Jonathan},
  year    = {2018},
  month   = {01},
  pages   = {1-12},
  title   = {Dependable Content Distribution in D2D-Based Cooperative Vehicular Networks: A Big Data-Integrated Coalition Game Approach},
  volume  = {PP},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  doi     = {10.1109/TITS.2017.2771519}
}

@article{a_big_data_analytics_based_methodology,
  title     = {A big data analytics based methodology for strategic decision making},
  author    = {{\"O}zemre, Murat and Kabadurmus, Ozgur},
  journal   = {Journal of Enterprise Information Management},
  volume    = {33},
  number    = {6},
  pages     = {1467--1490},
  year      = {2020},
  publisher = {Emerald Publishing Limited}
}

@article{toward_scalable_systems_big_data_analytics,
  title     = {Toward scalable systems for big data analytics: A technology tutorial},
  author    = {Hu, Han and Wen, Yonggang and Chua, Tat-Seng and Li, Xuelong},
  journal   = {IEEE access},
  volume    = {2},
  pages     = {652--687},
  year      = {2014},
  publisher = {IEEE}
}

@article{scalable_framework_for_provisioning_large_scale_iot_deployments,
  author     = {V\"{o}gler, Michael and Schleicher, Johannes M. and Inzinger, Christian and Dustdar, Schahram},
  title      = {A Scalable Framework for Provisioning Large-Scale IoT Deployments},
  year       = {2016},
  issue_date = {April 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {16},
  number     = {2},
  issn       = {1533-5399},
  url        = {https://doi.org/10.1145/2850416},
  doi        = {10.1145/2850416},
  abstract   = {Internet of Things (IoT) devices are usually considered external application dependencies that only provide data or process and execute simple instructions. The recent emergence of IoT devices with embedded execution environments allows practitioners to deploy and execute custom application logic directly on the device. This approach fundamentally changes the overall process of designing, developing, deploying, and managing IoT systems. However, these devices exhibit significant differences in available execution environments, processing, and storage capabilities. To accommodate this diversity, a structured approach is needed to uniformly and transparently deploy application components onto a large number of heterogeneous devices. This is especially important in the context of large-scale IoT systems, such as in the smart city domain. In this article, we present LEONORE, an infrastructure toolset that provides elastic provisioning of application components on resource-constrained and heterogeneous edge devices in large-scale IoT deployments. LEONORE supports push-based as well as pull-based deployments. To improve scalability and reduce generated network traffic between cloud and edge infrastructure, we present a distributed provisioning approach that deploys LEONORE local nodes within the deployment infrastructure close to the actual edge devices. We show that our solution is able to elastically provision large numbers of devices using a testbed based on a real-world industry scenario.},
  journal    = {ACM Trans. Internet Technol.},
  month      = {mar},
  articleno  = {11},
  numpages   = {20},
  keywords   = {framework, resource-constrained, large-scale, IoT, provisioning, gateway}
}

@inproceedings{modeling_requirements_big_data,
  title        = {Modeling the requirements for big data application using goal oriented approach},
  author       = {Eridaputra, Hanif and Hendradjaya, Bayu and Sunindyo, Wikan Danar},
  booktitle    = {2014 international conference on data and software engineering (ICODSE)},
  pages        = {1--6},
  year         = {2014},
  organization = {IEEE}
}

@misc{big_data_amount_statista,
  author       = {Taylor, Petroc},
  howpublished = {Statista.com \url{https://www.statista.com/statistics/871513/worldwide-data-created/}},
  title        = {Volume of data/information created, captured, copied, and consumed worldwide from 2010 to 2020, with forecasts from 2021 to 2025},
  year         = {2022}
}

% availability

@article{ha_computer_systems,
  title     = {High-availability computer systems},
  author    = {Gray, Jim and Siewiorek, Daniel P.},
  journal   = {Computer},
  volume    = {24},
  number    = {9},
  pages     = {39--48},
  year      = {1991},
  publisher = {IEEE}
}

@inproceedings{detecting_performance_degredation,
  title        = {Detecting performance degradation of software-intensive systems in 
                  the presence of trends and long-range dependence},
  author       = {Artemov, Alexey and Burnaev, Evgeny},
  booktitle    = {2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW)},
  pages        = {29--36},
  year         = {2016},
  organization = {IEEE}
}

% architecture
@article{navigating_architecture,
  title     = {Navigating the next-generation application architecture},
  author    = {Hutchinson, Chuck and Ward, Jeff and Castilon, Karen},
  journal   = {IT professional},
  volume    = {11},
  number    = {2},
  pages     = {18--22},
  year      = {2009},
  publisher = {IEEE}
}

@incollection{big_data_architecture,
  title     = {Big data application architecture},
  author    = {Sawant, Nitin and Shah, Himanshu},
  booktitle = {Big data Application Architecture Q \& A},
  pages     = {9--28},
  year      = {2013},
  publisher = {Springer}
}

@article{brief_history_cloud_application_architecture,
  title     = {A brief history of cloud application architectures},
  author    = {Kratzke, Nane},
  journal   = {Applied Sciences},
  volume    = {8},
  number    = {8},
  pages     = {1368},
  year      = {2018},
  publisher = {MDPI}
}

 @misc{application_architecture_def,
  title        = {What is an application architecture?},
  howpublished = {Red Hat \url{https://www.redhat.com/en/topics/cloud-native-apps/what-is-an-application-architecture}},
  month        = 3,
  year         = 2020,
  key          = {What is an application architecture}
}

@article{kappa_lambda,
  title        = {The Lambda and the Kappa},
  volume       = {21},
  issn         = {1941-0131},
  doi          = {10.1109/MIC.2017.3481351},
  abstractnote = {Whether lambda or kappa, there's no free lunch!},
  number       = {5},
  journal      = {IEEE Internet Computing},
  author       = {Lin, Jimmy},
  year         = {2017},
  pages        = {60--66}
}

% architecture examples
@inproceedings{facebook_data_center_arch,
  title        = {Facebook's data center network architecture},
  author       = {Farrington, Nathan and Andreyev, Alexey},
  booktitle    = {2013 Optical Interconnects Conference},
  pages        = {49--50},
  year         = {2013},
  organization = {IEEE}
}

@misc{twitter_arch_blog,
  author       = {Hashemi, Mazdak},
  howpublished = {Twitter Blog \url{https://blog.twitter.com/engineering/en_us/topics/infrastructure/2017/the-infrastructure-behind-twitter-scale}},
  title        = {The Infrastructure Behind Twitter: Scale},
  year         = {2017}
}

% tehnologije
@misc{tech_opensearch,
  title        = {Introducing OpenSearch},
  howpublished = {Amazon Web Services \url{https://aws.amazon.com/blogs/opensource/introducing-opensearch/}},
  month        = 4,
  year         = 2021,
  author       = {Meadows, Carl and Graybill, Jules and Davis, Kyle and Shah, Mehul}
}

@misc{tech_kafka,
  title        = {Apache Kafka},
  howpublished = {The Apache Software Foundation \url{https://kafka.apache.org/}},
  month        = 12,
  year         = 2022,
  key          = {Apache Kafka}
}

@misc{tech_helm,
  key          = {helm},
  howpublished = {Helm \url{https://helm.sh/}},
  title        = {Helm},
  year         = {2022}
}

@book{tech_ansible,
  title     = {Ansible: Up and Running: Automating configuration management and deployment the easy way},
  author    = {Hochstein, Lorin and Moser, Rene},
  year      = {2017},
  publisher = {" O'Reilly Media, Inc."}
}

@book{tech_vagrant,
  title     = {Vagrant: up and running: create and manage virtualized development environments},
  author    = {Hashimoto, Mitchell},
  year      = {2013},
  publisher = {" O'Reilly Media, Inc."}
}

@book{tech_terraform,
  title     = {Terraform: Up and Running},
  author    = {Brikman, Yevgeniy},
  year      = {2022},
  publisher = {" O'Reilly Media, Inc."}
}

@article{tech_docker,
  title     = {Docker [software engineering]},
  author    = {Anderson, Charles},
  journal   = {Ieee Software},
  volume    = {32},
  number    = {3},
  pages     = {102--c3},
  year      = {2015},
  publisher = {IEEE}
}

@book{tech_kubernetes,
  title     = {Kubernetes: up and running},
  author    = {Burns, Brendan and Beda, Joe and Hightower, Kelsey and Evenson, Lachlan},
  year      = {2022},
  publisher = {" O'Reilly Media, Inc."}
}

@book{tech_hadoop,
  title     = {Hadoop: The definitive guide},
  author    = {White, Tom},
  year      = {2012},
  publisher = {" O'Reilly Media, Inc."}
}

# cloud computing
@inproceedings{cloud_computing_overview,
  title        = {Cloud computing: An overview},
  author       = {Qian, Ling and Luo, Zhiguo and Du, Yujian and Guo, Leitao},
  booktitle    = {Cloud Computing: First International Conference, CloudCom 2009, Beijing, China, December 1-4, 2009. Proceedings 1},
  pages        = {626--631},
  year         = {2009},
  organization = {Springer}
}

@article{cloud_computing_today_tomorrow,
  title     = {Cloud computing: Today and tomorrow.},
  author    = {Kim, Won},
  journal   = {J. Object Technol.},
  volume    = {8},
  number    = {1},
  pages     = {65--72},
  year      = {2009},
  publisher = {Citeseer}
}

@inproceedings{cloud_computing_issues_challanges,
  title        = {Cloud computing: issues and challenges},
  author       = {Dillon, Tharam and Wu, Chen and Chang, Elizabeth},
  booktitle    = {2010 24th IEEE international conference on advanced information networking and applications},
  pages        = {27--33},
  year         = {2010},
  organization = {Ieee}
}

# virtualization

@inproceedings{virtualisation_vs_containerization,
  title        = {Virtualization vs containerization to support paas},
  author       = {Dua, Rajdeep and Raja, A Reddy and Kakadia, Dharmesh},
  booktitle    = {2014 IEEE International Conference on Cloud Engineering},
  pages        = {610--614},
  year         = {2014},
  organization = {IEEE}
}

@inproceedings{virtualization_survey,
  title        = {Virtualization: A survey on concepts, taxonomy and associated security issues},
  author       = {Sahoo, Jyotiprakash and Mohapatra, Subasish and Lath, Radha},
  booktitle    = {2010 second international conference on computer and network technology},
  pages        = {222--226},
  year         = {2010},
  organization = {IEEE}
}

# orchestration

@inproceedings{container_orchestration,
  title        = {Container orchestration engines: A thorough functional and performance comparison},
  author       = {Al Jawarneh, Isam Mashhour and Bellavista, Paolo and Bosi, Filippo and Foschini, Luca and Martuscelli, Giuseppe and Montanari, Rebecca and Palopoli, Amedeo},
  booktitle    = {ICC 2019-2019 IEEE International Conference on Communications (ICC)},
  pages        = {1--6},
  year         = {2019},
  organization = {IEEE}
}

@inproceedings{container_orchestrators_comparison,
  title        = {The comparison of container orchestrators},
  author       = {Mercl, Lubos and Pavlik, Jakub},
  booktitle    = {Third International Congress on Information and Communication Technology: ICICT 2018, London},
  pages        = {677--685},
  year         = {2019},
  organization = {Springer}
}

# distributed file systems

@article{distributed_file_systems,
  title     = {Distributed file systems: Concepts and examples},
  author    = {Levy, Eliezer and Silberschatz, Abraham},
  journal   = {ACM Computing Surveys (CSUR)},
  volume    = {22},
  number    = {4},
  pages     = {321--374},
  year      = {1990},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{hadoop,
  title        = {The hadoop distributed file system},
  author       = {Shvachko, Konstantin and Kuang, Hairong and Radia, Sanjay and Chansler, Robert},
  booktitle    = {2010 IEEE 26th symposium on mass storage systems and technologies (MSST)},
  pages        = {1--10},
  year         = {2010},
  organization = {Ieee}
}

@inproceedings{big_data_review,
  title        = {Big data: A review},
  author       = {Sagiroglu, Seref and Sinanc, Duygu},
  booktitle    = {2013 international conference on collaboration technologies and systems (CTS)},
  pages        = {42--47},
  year         = {2013},
  organization = {IEEE}
}

# data warehouse

@article{data_warehouse_overview,
  title     = {An overview of data warehousing and OLAP technology},
  author    = {Chaudhuri, Surajit and Dayal, Umeshwar},
  journal   = {ACM Sigmod record},
  volume    = {26},
  number    = {1},
  pages     = {65--74},
  year      = {1997},
  publisher = {ACM New York, NY, USA}
}

@inproceedings{hive_intro,
  title        = {Hive-a petabyte scale data warehouse using hadoop},
  author       = {Thusoo, Ashish and Sarma, Joydeep Sen and Jain, Namit and Shao, Zheng and Chakka, Prasad and Zhang, Ning and Antony, Suresh and Liu, Hao and Murthy, Raghotham},
  booktitle    = {2010 IEEE 26th international conference on data engineering (ICDE 2010)},
  pages        = {996--1005},
  year         = {2010},
  organization = {IEEE}
}

@inproceedings{hive_warehouse,
  title     = {Apache hive: From mapreduce to enterprise-grade big data warehousing},
  author    = {Camacho-Rodr{\'\i}guez, Jes{\'u}s and Chauhan, Ashutosh and Gates, Alan and Koifman, Eugene and O'Malley, Owen and Garg, Vineet and Haindrich, Zoltan and Shelukhin, Sergey and Jayachandran, Prasanth and Seth, Siddharth and others},
  booktitle = {Proceedings of the 2019 International Conference on Management of Data},
  pages     = {1773--1786},
  year      = {2019}
}

# NoSQL

@article{nosql,
  title   = {Nosql database: New era of databases for big data analytics-classification, characteristics and comparison},
  author  = {Moniruzzaman, ABM and Hossain, Syed Akhter},
  journal = {arXiv preprint arXiv:1307.0191},
  year    = {2013}
}

@inproceedings{perf_comp_sql_nosql,
  title        = {A performance comparison of SQL and NoSQL databases},
  author       = {Li, Yishan and Manoharan, Sathiamoorthy},
  booktitle    = {2013 IEEE Pacific Rim conference on communications, computers and signal processing (PACRIM)},
  pages        = {15--19},
  year         = {2013},
  organization = {IEEE}
}

@article{nosql_types,
  title   = {Type of NOSQL databases and its comparison with relational databases},
  author  = {Nayak, Ameya and Poriya, Anil and Poojary, Dikshay},
  journal = {International Journal of Applied Information Systems},
  volume  = {5},
  number  = {4},
  pages   = {16--19},
  year    = {2013}
}

@inproceedings{nosql_survey,
  title        = {Survey on NoSQL database},
  author       = {Han, Jing and Haihong, Ee and Le, Guan and Du, Jian},
  booktitle    = {2011 6th international conference on pervasive computing and applications},
  pages        = {363--366},
  year         = {2011},
  organization = {IEEE}
}

@article{nosql_comparative,
  title     = {Comparative study of the new generation, agile, scalable, high performance NOSQL databases},
  author    = {Tauro, Clarence JM and Aravindh, Shreeharsha and Shreeharsha, AB},
  journal   = {International Journal of Computer Applications},
  volume    = {48},
  number    = {20},
  pages     = {1--4},
  year      = {2012},
  publisher = {International Journal of Computer Applications, 244 5 th Avenue,\# 1526, New~…}
}

@article{choosing_right_nosql,
  title        = {Choosing the right NoSQL database for the job: a quality attribute evaluation},
  volume       = {2},
  issn         = {2196-1115},
  doi          = {10.1186/s40537-015-0025-0},
  abstractnote = {For over forty years, relational databases have been the leading model for data storage, retrieval and management. However, due to increasing needs for scalability and performance, alternative systems have emerged, namely NoSQL technology. The rising interest in NoSQL technology, as well as the growth in the number of use case scenarios, over the last few years resulted in an increasing number of evaluations and comparisons among competing NoSQL technologies. While most research work mostly focuses on performance evaluation using standard benchmarks, it is important to notice that the architecture of real world systems is not only driven by performance requirements, but has to comprehensively include many other quality attribute requirements. Software quality attributes form the basis from which software engineers and architects develop software and make design decisions. Yet, there has been no quality attribute focused survey or classification of NoSQL databases where databases are compared with regards to their suitability for quality attributes common on the design of enterprise systems. To fill this gap, and aid software engineers and architects, in this article, we survey and create a concise and up-to-date comparison of NoSQL engines, identifying their most beneficial use case scenarios from the software engineer point of view and the quality attributes that each of them is most suited to.},
  number       = {1},
  journal      = {Journal of Big Data},
  author       = {Lourenço, João Ricardo and Cabral, Bruno and Carreiro, Paulo and Vieira, Marco and Bernardino, Jorge},
  year         = {2015},
  month        = {Aug},
  pages        = {18}
}

# sql

@inproceedings{galera,
  title        = {A high availability (HA) MariaDB Galera Cluster across data center with optimized WRR scheduling algorithm of LVS - TUN},
  doi          = {10.1109/TSSA.2015.7440452},
  abstractnote = {Data availability and reliability is very important along with the growth of information and communication technology services today. Needs of the powerful and affordable database system infrastructure to be the most considered thing by the application service provider. This paper presents the powerful and scalable database open source solution infrastructure which can be distributed across the data center in the world to provide any application or content services. Database infrastructure in this paper using MariaDB Galera Cluster which geographically distributed across data center and Linux Virtual Server (LVS)-Tunnel with optimized weighted round robin algorithm as the load balancer. Optimization in this weighted round robin algorithm are focused on assignment value of weight, based on the condition of database server status. The condition include total active thread (active connected client) and Query per Second Average.},
  booktitle    = {2015 9th International Conference on Telecommunication Systems Services and Applications (TSSA)},
  author       = {Aditya, Bagus and Juhana, Tutun},
  year         = {2015},
  month        = {Nov},
  pages        = {1--5}
}

# search engine

@article{search_engine_solr_elastic,
  title   = {An analysis on the comparison of the performance and configuration features of big data tools Solr and Elasticsearch},
  author  = {AKCA, Mustafa Ali and Aydo{\u{g}}an, Tuncay and {\.I}lku{\c{c}}ar, Muhammer},
  journal = {International Journal of Intelligent Systems and Applications in Engineering},
  volume  = {4},
  number  = {Special Issue-1},
  pages   = {8--12},
  year    = {2016}
}

@article{search_engine_general,
  title     = {Big data processing for full-text search and visualization with Elasticsearch},
  author    = {Voit, Aleksei and Stankus, Aleksei and Magomedov, Shamil and Ivanova, Irina},
  journal   = {International journal of advanced computer science and applications},
  volume    = {8},
  number    = {12},
  year      = {2017},
  publisher = {Science and Information (SAI) Organization Limited}
}

# integration

@inproceedings{etl_conceptual,
  title     = {Conceptual modeling for ETL processes},
  author    = {Vassiliadis, Panos and Simitsis, Alkis and Skiadopoulos, Spiros},
  booktitle = {Proceedings of the 5th ACM international workshop on Data Warehousing and OLAP},
  pages     = {14--21},
  year      = {2002}
}

@inproceedings{etl_designing,
  title     = {Designing ETL processes using semantic web technologies},
  author    = {Skoutas, Dimitrios and Simitsis, Alkis},
  booktitle = {Proceedings of the 9th ACM international workshop on Data warehousing and OLAP},
  pages     = {67--74},
  year      = {2006}
}

@inproceedings{etl_efficiency_eval,
  address   = {New York, NY, USA},
  series    = {{SAC} '11},
  title     = {Efficiency evaluation of open source {ETL} tools},
  isbn      = {978-1-4503-0113-8},
  url       = {https://doi.org/10.1145/1982185.1982251},
  doi       = {10.1145/1982185.1982251},
  abstract  = {Business intelligence (BI) is considered to have a high impact on businesses. Research activity has risen in the last years. An important part of BI systems is a well performing implementation of the Extract, Transform, and Load (ETL) process. In typical BI projects, implementing the ETL process can be the task with the greatest effort. However, little work is published on ETL applications and in particular on open source ETL tools. We have analyzed open source ETL tools especially with regard to their performance. In this paper we present the analysis' background and highlight related work. We then sketch the test setup, show the detailed results for Talend Open Studio and Pentaho Data Integration, and discuss our observations. Eventually, we draw a conclusion and point out future work.},
  urldate   = {2023-04-10},
  booktitle = {Proceedings of the 2011 {ACM} {Symposium} on {Applied} {Computing}},
  publisher = {Association for Computing Machinery},
  author    = {Majchrzak, Tim A. and Jansen, Tobias and Kuchen, Herbert},
  month     = mar,
  year      = {2011},
  keywords  = {BI, business intelligence, ETL, extract, load, transform},
  pages     = {287--294}
}

@article{bi_survey,
  title        = {A Survey of Open Source Tools for Business Intelligence},
  volume       = {5},
  rights       = {Access limited to members},
  issn         = {1548-3924},
  doi          = {10.4018/jdwm.2009070103},
  abstractnote = {The industrial use of open source Business Intelligence (BI) tools is becoming more common, but is still not as widespread as for other types of software. It is therefore of interest to explore which possibilities are available for open source BI and compare the tools. In this survey article, we con...},
  number       = {3},
  journal      = {International Journal of Data Warehousing and Mining (IJDWM)},
  publisher    = {IGI Global},
  author       = {Thomsen, Christian and Pedersen, Torben Bach},
  year         = {2009},
  month        = {Jul},
  pages        = {56--75},
  language     = {en}
}

@article{etl_survey,
  title     = {A survey of ETL tools},
  author    = {Mali, Nilesh and Bojewar, Sachin},
  journal   = {International Journal of Computer Techniques},
  volume    = {2},
  number    = {5},
  pages     = {20--27},
  year      = {2015},
  publisher = {Oct}
}

# machine learning

@article{spark_flink_comparison,
  title    = {A comparison on scalability for batch big data processing on {Apache} {Spark} and {Apache} {Flink}},
  volume   = {2},
  issn     = {2058-6345},
  url      = {https://doi.org/10.1186/s41044-016-0020-2},
  doi      = {10.1186/s41044-016-0020-2},
  abstract = {The large amounts of data have created a need for new frameworks for processing. The MapReduce model is a framework for processing and generating large-scale datasets with parallel and distributed algorithms. Apache Spark is a fast and general engine for large-scale data processing based on the MapReduce model. The main feature of Spark is the in-memory computation. Recently a novel framework called Apache Flink has emerged, focused on distributed stream and batch data processing. In this paper we perform a comparative study on the scalability of these two frameworks using the corresponding Machine Learning libraries for batch data processing. Additionally we analyze the performance of the two Machine Learning libraries that Spark currently has, MLlib and ML. For the experiments, the same algorithms and the same dataset are being used. Experimental results show that Spark MLlib has better perfomance and overall lower runtimes than Flink.},
  number   = {1},
  urldate  = {2023-04-14},
  journal  = {Big Data Analytics},
  author   = {García-Gil, Diego and Ramírez-Gallego, Sergio and García, Salvador and Herrera, Francisco},
  month    = mar,
  year     = {2017},
  keywords = {Big data, Machine learning, Flink, MapReduce, Spark},
  pages    = {1}
}

@article{ml_survey,
  title    = {A survey of machine learning for big data processing},
  volume   = {2016},
  issn     = {1687-6180},
  url      = {https://doi.org/10.1186/s13634-016-0355-x},
  doi      = {10.1186/s13634-016-0355-x},
  abstract = {There is no doubt that big data are now rapidly expanding in all science and engineering domains. While the potential of these massive data is undoubtedly significant, fully making sense of them requires new ways of thinking and novel learning techniques to address the various challenges. In this paper, we present a literature survey of the latest advances in researches on machine learning for big data processing. First, we review the machine learning techniques and highlight some promising learning methods in recent studies, such as representation learning, deep learning, distributed and parallel learning, transfer learning, active learning, and kernel-based learning. Next, we focus on the analysis and discussions about the challenges and possible solutions of machine learning for big data. Following that, we investigate the close connections of machine learning with signal processing techniques for big data processing. Finally, we outline several open issues and research trends.},
  language = {en},
  number   = {1},
  urldate  = {2023-04-16},
  journal  = {EURASIP Journal on Advances in Signal Processing},
  author   = {Qiu, Junfei and Wu, Qihui and Ding, Guoru and Xu, Yuhua and Feng, Shuo},
  month    = may,
  year     = {2016},
  keywords = {Big data, Data mining, Machine learning, Signal processing techniques},
  pages    = {67}
}

@article{ml_opportunities_challenges,
  title      = {Machine learning on big data: {Opportunities} and challenges},
  volume     = {237},
  issn       = {0925-2312},
  shorttitle = {Machine learning on big data},
  url        = {https://www.sciencedirect.com/science/article/pii/S0925231217300577},
  doi        = {10.1016/j.neucom.2017.01.026},
  abstract   = {Machine learning (ML) is continuously unleashing its power in a wide range of applications. It has been pushed to the forefront in recent years partly owing to the advent of big data. ML algorithms have never been better promised while challenged by big data. Big data enables ML algorithms to uncover more fine-grained patterns and make more timely and accurate predictions than ever before; on the other hand, it presents major challenges to ML such as model scalability and distributed computing. In this paper, we introduce a framework of ML on big data (MLBiD) to guide the discussion of its opportunities and challenges. The framework is centered on ML which follows the phases of preprocessing, learning, and evaluation. In addition, the framework is also comprised of four other components, namely big data, user, domain, and system. The phases of ML and the components of MLBiD provide directions for identification of associated opportunities and challenges and open up future work in many unexplored or under explored research areas.},
  language   = {en},
  urldate    = {2023-04-16},
  journal    = {Neurocomputing},
  author     = {Zhou, Lina and Pan, Shimei and Wang, Jianwu and Vasilakos, Athanasios V.},
  month      = may,
  year       = {2017},
  keywords   = {Big data, Data preprocessing, Evaluation, Machine learning, Parallelization},
  pages      = {350--361}
}

# visualization


@inproceedings{bd_visualization_tools_survey,
  address    = {Madrid, Spain},
  title      = {Big {Data} {Visualization} {Tools}: {A} {Survey} - {The} {New} {Paradigms}, {Methodologies} and {Tools} for {Large} {Data} {Sets} {Visualization}:},
  isbn       = {978-989-758-255-4},
  shorttitle = {Big {Data} {Visualization} {Tools}},
  url        = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006484102960305},
  doi        = {10.5220/0006484102960305},
  language   = {en},
  urldate    = {2023-04-16},
  booktitle  = {Proceedings of the 6th {International} {Conference} on {Data} {Science}, {Technology} and {Applications}},
  publisher  = {SCITEPRESS - Science and Technology Publications},
  author     = {Caldarola, Enrico G. and Rinaldi, Antonio M.},
  year       = {2017},
  pages      = {296--305}
}

@misc{bd_visualization_tools,
  title     = {Big {Data} {Visualization} {Tools}},
  url       = {http://arxiv.org/abs/1801.08336},
  doi       = {10.48550/arXiv.1801.08336},
  abstract  = {Data visualization is the presentation of data in a pictorial or graphical format, and a data visualization tool is the software that generates this presentation. Data visualization provides users with intuitive means to interactively explore and analyze data, enabling them to effectively identify interesting patterns, infer correlations and causalities, and supports sense-making activities.},
  urldate   = {2023-04-16},
  publisher = {arXiv},
  author    = {Bikakis, Nikos},
  month     = feb,
  year      = {2018},
  note      = {arXiv:1801.08336 [cs]},
  keywords  = {97R50, 68P05, 68P15, Computer Science - Databases, Computer Science - Graphics, Computer Science - Human-Computer Interaction, E.1, H.2.8, H.4, H.5.2}
}

@misc{visualization_ibm,
  key        = {What is},
  title      = {What is {Data} {Visualization}? {\textbar} {IBM}},
  shorttitle = {What is {Data} {Visualization}?},
  url        = {https://www.ibm.com/topics/data-visualization},
  abstract   = {Learn how data visualization can improve understanding and analyses, enabling better and faster decision making.},
  language   = {en-us},
  urldate    = {2023-04-25}
}

# data governence

@article{exploring_data_governance,
  series       = {The 9th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2018) / The 8th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2018) / Affiliated Workshops},
  title        = {Exploring Big Data Governance Frameworks},
  volume       = {141},
  issn         = {1877-0509},
  doi          = {10.1016/j.procs.2018.10.181},
  abstractnote = {The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization’s data, exploiting it in the organization’s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework.},
  journal      = {Procedia Computer Science},
  author       = {Al-Badi, Ali and Tarhini, Ali and Khan, Asharul Islam},
  year         = {2018},
  month        = {Jan},
  pages        = {271--277},
  collection   = {The 9th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2018) / The 8th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2018) / Affiliated Workshops},
  language     = {en}
}

# streaming

@article{stream_analysis_systematic_literature_review,
  title        = {Big data stream analysis: a systematic literature review},
  volume       = {6},
  doi          = {10.1186/s40537-019-0210-7},
  abstractnote = {Recently, big data streams have become ubiquitous due to the fact that a number of applications generate a huge amount of data at a great velocity. This made it difficult for existing data mining tools, technologies, methods, and techniques to be applied directly on big data streams due to the inherent dynamic characteristics of big data. In this paper, a systematic review of big data streams analysis which employed a rigorous and methodical approach to look at the trends of big data stream tools and technologies as well as methods and techniques employed in analysing big data streams. It provides a global view of big data stream tools and technologies and its comparisons. Three major databases, Scopus, ScienceDirect and EBSCO, which indexes journals and conferences that are promoted by entities such as IEEE, ACM, SpringerLink, and Elsevier were explored as data sources. Out of the initial 2295 papers that resulted from the first search string, 47 papers were found to be relevant to our research questions after implementing the inclusion and exclusion criteria. The study found that scalability, privacy and load balancing issues as well as empirical analysis of big data streams and technologies are still open for further research efforts. We also found that although, significant research efforts have been directed to real-time analysis of big data stream not much attention has been given to the preprocessing stage of big data streams. Only a few big data streaming tools and technologies can do all of the batch, streaming, and iterative jobs; there seems to be no big data tool and technology that offers all the key features required for now and standard benchmark dataset for big data streaming analytics has not been widely adopted. In conclusion, it was recommended that research efforts should be geared towards developing scalable frameworks and algorithms that will accommodate data stream computing mode, effective resource allocation strategy and parallelization issues to cope with the ever-growing size and complexity of data.},
  journal      = {Journal of Big Data},
  author       = {Kolajo, Taiwo and Daramola, Olawande and Adebiyi, Ayodele},
  year         = {2019},
  month        = {Jun},
  pages        = {47}
}

# algo

@article{map_reduce,
  title     = {MapReduce: simplified data processing on large clusters},
  author    = {Dean, Jeffrey and Ghemawat, Sanjay},
  journal   = {Communications of the ACM},
  volume    = {51},
  number    = {1},
  pages     = {107--113},
  year      = {2008},
  publisher = {ACM New York, NY, USA}
}

# fault tolerance

@article{fault_tolerance,
  title        = {Fault tolerance in big data storage and processing systems: A review on challenges and solutions},
  volume       = {13},
  issn         = {2090-4479},
  doi          = {10.1016/j.asej.2021.06.024},
  abstractnote = {Big data systems are sufficiently stable to store and process a massive volume of rapidly changing data. However, big data systems are composed of large-scale hardware resources that make their subspecies easily fail. Fault tolerance is the main property of such systems because it maintains availability, reliability, and constant performance during faults. Achieving an efficient fault tolerance solution in a big data system is challenging because fault tolerance must meet some constraints related to the system performance and resource consumption. This study aims to provide a consistent understanding of fault tolerance in big data systems and highlights common challenges that hinder the improvement in fault tolerance efficiency. The fault tolerance solutions applied by previous studies intended to address the identified challenges are reviewed. The paper also presents a perceptive discussion of the findings derived from previous studies and proposes a list of future directions to address the fault tolerance challenges.},
  number       = {2},
  journal      = {Ain Shams Engineering Journal},
  author       = {Saadoon, Muntadher and Ab. Hamid, Siti Hafizah and Sofian, Hazrina and Altarturi, Hamza H. M. and Azizul, Zati Hakim and Nasuha, Nur},
  year         = {2022},
  month        = {Mar},
  pages        = {101538--101550},
  language     = {en}
}

@inproceedings{predicting_faults,
  title     = {Predicting Scheduling Failures in the Cloud: A Case Study with Google Clusters and Hadoop on Amazon EMR},
  doi       = {10.1109/HPCC-CSS-ICESS.2015.170},
  booktitle = {2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems},
  author    = {Soualhia, Mbarka and Khomh, Foutse and Tahar, Sofiène},
  year      = {2015},
  month     = {Aug},
  pages     = {58--65}
}

@article{reed_solomon,
  title        = {Polynomial Codes Over Certain Finite Fields},
  volume       = {8},
  issn         = {0368-4245},
  doi          = {10.1137/0108018},
  abstractnote = {We study certain projections of binary linear codes onto larger fields. These projections include the well-known projection of the extended Golay [24,12,8] code onto the hexacode over $mbox{GF}(4)$ and the projection of the Reed--Muller code R(2,5) onto the unique self-dual [8,4,4] code over $mbox{GF}(4)$. We give acharacterization of these projections, and we construct several binary linear codes which have best known optimal parameters, for instance, [20,11,5], [40,22,8], [48,21,12], and [72,31,16]. We also relate the automorphism group of a quaternary code to that of the corresponding binary code.},
  number       = {2},
  journal      = {Journal of the Society for Industrial and Applied Mathematics},
  publisher    = {Society for Industrial and Applied Mathematics},
  author       = {Reed, I. S. and Solomon, G.},
  year         = {1960},
  month        = {Jun},
  pages        = {300--304}
}

# testing

@article{babel_testing,
  title        = {Babel: A Generic Benchmarking Platform for Big Data Architectures},
  volume       = {24},
  issn         = {2214-5796},
  doi          = {10.1016/j.bdr.2021.100186},
  abstractnote = {In this era of big and fast data, software architects tend to find it really hard to make consistent decisions about which architecture and technologies are ideal for a certain business need. It is even harder to make them while dealing with the scarcity of clear methodologies, best practices and reference architectures. In this prospect, architecture evaluation through benchmarking can be of great interest, as it enables the detection of performance anomalies or bottlenecks as you go. The problem when talking about Big Data benchmarking, is that existing solutions remain technology-related, and do not deal with the heterogeneous aspect of complex architectures. In addition to that, businesses are in general dealing with multi-layered complex systems, involving various technologies, paradigms and micro-architectures. This means that the benchmarking solution must be able to give fine-grained insights about each of the layers. A successful benchmarking system must also be seamless, easy to use, scalable, and preferably cloud native. To satisfy these requirements, we designed and implemented Babel, a generic Big Data benchmarking platform, that insures an end-to-end performance evaluation and monitoring. We present in this paper the principles, architecture, integration and deployment steps of Babel.},
  journal      = {Big Data Research},
  author       = {Sfaxi, Lilia and Ben Aissa, Mohamed Mehdi},
  year         = {2021},
  month        = {May},
  language     = {en}
}

@article{review_testing,
  title        = {Review Paper on Various Software Testing Techniques \& Strategies},
  issn         = {09754172, 09754350},
  doi          = {10.34257/GJCSTCVOL19IS2PG43},
  abstractnote = {Software testing is the process of running an application with the intent of finding software bugs (errors or other defects). Software applications demand has pushed the quality assurance of developed software towards new heights. It has been considered as the most critical stage of the software development life cycle. Testing can analyze the software item to identify the disparity between actual and prescribed conditions and to assess the characteristics of the software. Software testing leads to minimizing errors and cut down software costs. For this purpose, we discuss various software testing techniques and strategies. This paper aims to study diverse as well as improved software testing techniques for better quality assurance purposes.},
  journal      = {Global Journal of Computer Science and Technology},
  author       = {Anwar, Nahid and Kar, Susmita},
  year         = {2019},
  month        = {May},
  pages        = {43--49},
  language     = {en}
}

@article{chaos_engineering,
  title        = {Chaos Engineering},
  volume       = {33},
  issn         = {1937-4194},
  doi          = {10.1109/MS.2016.60},
  abstractnote = {Modern software-based services are implemented as distributed systems with complex behavior and failure modes. Many large tech organizations are using experimentation to verify such systems’ reliability. Netflix engineers call this approach chaos engineering. They’ve determined several principles underlying it and have used it to run experiments. This article is part of a theme issue on DevOps.},
  number       = {3},
  journal      = {IEEE Software},
  author       = {Basiri, Ali and Behnam, Niosha and de Rooij, Ruud and Hochstein, Lorin and Kosewski, Luke and Reynolds, Justin and Rosenthal, Casey},
  year         = {2016},
  month        = {May},
  pages        = {35--41}
}

@misc{chaos_mesh,
  key          = {chaos},
  title        = {Chaos Mesh},
  month        = {8},
  year         = {2023},
  howpublished = {\url{https://chaos-mesh.org/}},
  note         = {A Powerful Chaos Engineering Platform for Kubernetes},
  language     = {en}
}

# apps

@misc{jellyfin,
  key          = {Jellyfin},
  title        = {Jellyfin},
  url          = {https://jellyfin.org/},
  month        = {08},
  year         = {2023},
  howpublished = {\url{https://jellyfin.org/}},
  note         = {The volunteer-built media solution that puts you in control of your media. 
                  Stream to any device from your own server, with no strings attached.},
  language     = {en}
}

@misc{k6,
  key          = {K6},
  title        = {K6},
  howpublished = {\url{https://k6.io}},
  month        = {08},
  year         = {2023},
  note         = {k6 is an open-source tool and cloud service that makes load testing easy for developers and QA engineers.},
  language     = {en}
}
